<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Book Recommender System</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Book Recommender System</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="author-andrew-tran" class="level4">
<h4 class="anchored" data-anchor-id="author-andrew-tran">Author: Andrew Tran</h4>
</section>
<section id="blog-post-inspiration-and-objectives" class="level2">
<h2 class="anchored" data-anchor-id="blog-post-inspiration-and-objectives">Blog Post Inspiration and Objectives</h2>
<p>In this blog post, I was hoping to take on the classic beginner/intermediate challenge of creating a simple Machine Learning recommendation system, imitating ones used at Big-Tech companies such as Netflix. Additionally, with so many examples online about Machine Learning movie recommendation systems, I decided to look to establish this system on another area which has always piqued my interest: books. With that said, let’s try to analyze and create this system with some Machine Learning:</p>
</section>
<section id="data-preprocessing---cleaning-and-analytics" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing---cleaning-and-analytics">Data Preprocessing - Cleaning and Analytics</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>color <span class="op">=</span> sns.color_palette()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> average_precision_score, roc_auc_score, precision_recall_fscore_support, confusion_matrix, classification_report</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, pairwise_distances</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Model</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Input, Embedding, Flatten, dot</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">"fivethirtyeight"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First, we will read and display all of the initial datasets in our file system for this blog post, downloaded from Kaggle. These datasets contains loads of valuable information such as Book-ISBNS, user-ids for the (anonymous) users/reviewers, book ratings, etc.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reading and displaying all of the initial datasets</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>books_df <span class="op">=</span> pd.read_csv(<span class="st">"datasets/Books.csv"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>ratings_df <span class="op">=</span> pd.read_csv(<span class="st">"datasets/Ratings.csv"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>users_df <span class="op">=</span> pd.read_csv(<span class="st">"datasets/Users.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\andre\AppData\Local\Temp\ipykernel_7880\2730945584.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.
  books_df = pd.read_csv("datasets/Books.csv")</code></pre>
</div>
</div>
<p>For clarity on the constraints and parameters of the working datasets, I went to find high-level exploratory statistics on all of the datasets: shape, information about all of the entries, etc.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Determining the shape of each of the initial datasets</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>books_df.shape, ratings_df.shape, users_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>((271360, 8), (1149780, 3), (278858, 3))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Figuring out all of the columns (and their names) available for me to use in the dataset</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>books_df.columns, ratings_df.columns, users_df.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>(Index(['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher',
        'Image-URL-S', 'Image-URL-M', 'Image-URL-L'],
       dtype='object'),
 Index(['User-ID', 'ISBN', 'Book-Rating'], dtype='object'),
 Index(['User-ID', 'Location', 'Age'], dtype='object'))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Getting basic information about the all of the datasets</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>books_df.info(), ratings_df.info(), users_df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 271360 entries, 0 to 271359
Data columns (total 8 columns):
 #   Column               Non-Null Count   Dtype 
---  ------               --------------   ----- 
 0   ISBN                 271360 non-null  object
 1   Book-Title           271360 non-null  object
 2   Book-Author          271359 non-null  object
 3   Year-Of-Publication  271360 non-null  object
 4   Publisher            271358 non-null  object
 5   Image-URL-S          271360 non-null  object
 6   Image-URL-M          271360 non-null  object
 7   Image-URL-L          271357 non-null  object
dtypes: object(8)
memory usage: 16.6+ MB
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1149780 entries, 0 to 1149779
Data columns (total 3 columns):
 #   Column       Non-Null Count    Dtype 
---  ------       --------------    ----- 
 0   User-ID      1149780 non-null  int64 
 1   ISBN         1149780 non-null  object
 2   Book-Rating  1149780 non-null  int64 
dtypes: int64(2), object(1)
memory usage: 26.3+ MB
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 278858 entries, 0 to 278857
Data columns (total 3 columns):
 #   Column    Non-Null Count   Dtype  
---  ------    --------------   -----  
 0   User-ID   278858 non-null  int64  
 1   Location  278858 non-null  object 
 2   Age       168096 non-null  float64
dtypes: float64(1), int64(1), object(1)
memory usage: 6.4+ MB</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(None, None, None)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Seeing each of the dataframes individually</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>books_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ISBN</th>
<th data-quarto-table-cell-role="th">Book-Title</th>
<th data-quarto-table-cell-role="th">Book-Author</th>
<th data-quarto-table-cell-role="th">Year-Of-Publication</th>
<th data-quarto-table-cell-role="th">Publisher</th>
<th data-quarto-table-cell-role="th">Image-URL-S</th>
<th data-quarto-table-cell-role="th">Image-URL-M</th>
<th data-quarto-table-cell-role="th">Image-URL-L</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0195153448</td>
<td>Classical Mythology</td>
<td>Mark P. O. Morford</td>
<td>2002</td>
<td>Oxford University Press</td>
<td>http://images.amazon.com/images/P/0195153448.0...</td>
<td>http://images.amazon.com/images/P/0195153448.0...</td>
<td>http://images.amazon.com/images/P/0195153448.0...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0002005018</td>
<td>Clara Callan</td>
<td>Richard Bruce Wright</td>
<td>2001</td>
<td>HarperFlamingo Canada</td>
<td>http://images.amazon.com/images/P/0002005018.0...</td>
<td>http://images.amazon.com/images/P/0002005018.0...</td>
<td>http://images.amazon.com/images/P/0002005018.0...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0060973129</td>
<td>Decision in Normandy</td>
<td>Carlo D'Este</td>
<td>1991</td>
<td>HarperPerennial</td>
<td>http://images.amazon.com/images/P/0060973129.0...</td>
<td>http://images.amazon.com/images/P/0060973129.0...</td>
<td>http://images.amazon.com/images/P/0060973129.0...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0374157065</td>
<td>Flu: The Story of the Great Influenza Pandemic...</td>
<td>Gina Bari Kolata</td>
<td>1999</td>
<td>Farrar Straus Giroux</td>
<td>http://images.amazon.com/images/P/0374157065.0...</td>
<td>http://images.amazon.com/images/P/0374157065.0...</td>
<td>http://images.amazon.com/images/P/0374157065.0...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0393045218</td>
<td>The Mummies of Urumchi</td>
<td>E. J. W. Barber</td>
<td>1999</td>
<td>W. W. Norton &amp;amp; Company</td>
<td>http://images.amazon.com/images/P/0393045218.0...</td>
<td>http://images.amazon.com/images/P/0393045218.0...</td>
<td>http://images.amazon.com/images/P/0393045218.0...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">271355</td>
<td>0440400988</td>
<td>There's a Bat in Bunk Five</td>
<td>Paula Danziger</td>
<td>1988</td>
<td>Random House Childrens Pub (Mm)</td>
<td>http://images.amazon.com/images/P/0440400988.0...</td>
<td>http://images.amazon.com/images/P/0440400988.0...</td>
<td>http://images.amazon.com/images/P/0440400988.0...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">271356</td>
<td>0525447644</td>
<td>From One to One Hundred</td>
<td>Teri Sloat</td>
<td>1991</td>
<td>Dutton Books</td>
<td>http://images.amazon.com/images/P/0525447644.0...</td>
<td>http://images.amazon.com/images/P/0525447644.0...</td>
<td>http://images.amazon.com/images/P/0525447644.0...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">271357</td>
<td>006008667X</td>
<td>Lily Dale : The True Story of the Town that Ta...</td>
<td>Christine Wicker</td>
<td>2004</td>
<td>HarperSanFrancisco</td>
<td>http://images.amazon.com/images/P/006008667X.0...</td>
<td>http://images.amazon.com/images/P/006008667X.0...</td>
<td>http://images.amazon.com/images/P/006008667X.0...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">271358</td>
<td>0192126040</td>
<td>Republic (World's Classics)</td>
<td>Plato</td>
<td>1996</td>
<td>Oxford University Press</td>
<td>http://images.amazon.com/images/P/0192126040.0...</td>
<td>http://images.amazon.com/images/P/0192126040.0...</td>
<td>http://images.amazon.com/images/P/0192126040.0...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">271359</td>
<td>0767409752</td>
<td>A Guided Tour of Rene Descartes' Meditations o...</td>
<td>Christopher Biffle</td>
<td>2000</td>
<td>McGraw-Hill Humanities/Social Sciences/Languages</td>
<td>http://images.amazon.com/images/P/0767409752.0...</td>
<td>http://images.amazon.com/images/P/0767409752.0...</td>
<td>http://images.amazon.com/images/P/0767409752.0...</td>
</tr>
</tbody>
</table>

<p>271360 rows × 8 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>ratings_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">User-ID</th>
<th data-quarto-table-cell-role="th">ISBN</th>
<th data-quarto-table-cell-role="th">Book-Rating</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>276725</td>
<td>034545104X</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>276726</td>
<td>0155061224</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>276727</td>
<td>0446520802</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>276729</td>
<td>052165615X</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>276729</td>
<td>0521795028</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1149775</td>
<td>276704</td>
<td>1563526298</td>
<td>9</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1149776</td>
<td>276706</td>
<td>0679447156</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1149777</td>
<td>276709</td>
<td>0515107662</td>
<td>10</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1149778</td>
<td>276721</td>
<td>0590442449</td>
<td>10</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1149779</td>
<td>276723</td>
<td>05162443314</td>
<td>8</td>
</tr>
</tbody>
</table>

<p>1149780 rows × 3 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>users_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">User-ID</th>
<th data-quarto-table-cell-role="th">Location</th>
<th data-quarto-table-cell-role="th">Age</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>nyc, new york, usa</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>stockton, california, usa</td>
<td>18.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>moscow, yukon territory, russia</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>porto, v.n.gaia, portugal</td>
<td>17.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>farnborough, hants, united kingdom</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">278853</td>
<td>278854</td>
<td>portland, oregon, usa</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">278854</td>
<td>278855</td>
<td>tacoma, washington, united kingdom</td>
<td>50.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">278855</td>
<td>278856</td>
<td>brampton, ontario, canada</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">278856</td>
<td>278857</td>
<td>knoxville, tennessee, usa</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">278857</td>
<td>278858</td>
<td>dublin, n/a, ireland</td>
<td>NaN</td>
</tr>
</tbody>
</table>

<p>278858 rows × 3 columns</p>
</div>
</div>
</div>
<p>Before I can pass the datasets over to the Machine Learning model for training and prediction, I had to consolidate all of my datasets into one so that it would be more easier and convenient to analyze.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove any unnecessary columns (before merging)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>books_df.drop(columns<span class="op">=</span>[<span class="st">"Image-URL-S"</span>, <span class="st">"Image-URL-M"</span>, <span class="st">"Image-URL-L"</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>books_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ISBN</th>
<th data-quarto-table-cell-role="th">Book-Title</th>
<th data-quarto-table-cell-role="th">Book-Author</th>
<th data-quarto-table-cell-role="th">Year-Of-Publication</th>
<th data-quarto-table-cell-role="th">Publisher</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0195153448</td>
<td>Classical Mythology</td>
<td>Mark P. O. Morford</td>
<td>2002</td>
<td>Oxford University Press</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0002005018</td>
<td>Clara Callan</td>
<td>Richard Bruce Wright</td>
<td>2001</td>
<td>HarperFlamingo Canada</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0060973129</td>
<td>Decision in Normandy</td>
<td>Carlo D'Este</td>
<td>1991</td>
<td>HarperPerennial</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0374157065</td>
<td>Flu: The Story of the Great Influenza Pandemic...</td>
<td>Gina Bari Kolata</td>
<td>1999</td>
<td>Farrar Straus Giroux</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0393045218</td>
<td>The Mummies of Urumchi</td>
<td>E. J. W. Barber</td>
<td>1999</td>
<td>W. W. Norton &amp;amp; Company</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">271355</td>
<td>0440400988</td>
<td>There's a Bat in Bunk Five</td>
<td>Paula Danziger</td>
<td>1988</td>
<td>Random House Childrens Pub (Mm)</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">271356</td>
<td>0525447644</td>
<td>From One to One Hundred</td>
<td>Teri Sloat</td>
<td>1991</td>
<td>Dutton Books</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">271357</td>
<td>006008667X</td>
<td>Lily Dale : The True Story of the Town that Ta...</td>
<td>Christine Wicker</td>
<td>2004</td>
<td>HarperSanFrancisco</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">271358</td>
<td>0192126040</td>
<td>Republic (World's Classics)</td>
<td>Plato</td>
<td>1996</td>
<td>Oxford University Press</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">271359</td>
<td>0767409752</td>
<td>A Guided Tour of Rene Descartes' Meditations o...</td>
<td>Christopher Biffle</td>
<td>2000</td>
<td>McGraw-Hill Humanities/Social Sciences/Languages</td>
</tr>
</tbody>
</table>

<p>271360 rows × 5 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the books and ratings dataframes to have one &amp; inclusive dataframe, </span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># combining all book, user, and rating information</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.merge(books_df, ratings_df, on<span class="op">=</span><span class="st">"ISBN"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ISBN</th>
<th data-quarto-table-cell-role="th">Book-Title</th>
<th data-quarto-table-cell-role="th">Book-Author</th>
<th data-quarto-table-cell-role="th">Year-Of-Publication</th>
<th data-quarto-table-cell-role="th">Publisher</th>
<th data-quarto-table-cell-role="th">User-ID</th>
<th data-quarto-table-cell-role="th">Book-Rating</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0195153448</td>
<td>Classical Mythology</td>
<td>Mark P. O. Morford</td>
<td>2002</td>
<td>Oxford University Press</td>
<td>2</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0002005018</td>
<td>Clara Callan</td>
<td>Richard Bruce Wright</td>
<td>2001</td>
<td>HarperFlamingo Canada</td>
<td>8</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0002005018</td>
<td>Clara Callan</td>
<td>Richard Bruce Wright</td>
<td>2001</td>
<td>HarperFlamingo Canada</td>
<td>11400</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0002005018</td>
<td>Clara Callan</td>
<td>Richard Bruce Wright</td>
<td>2001</td>
<td>HarperFlamingo Canada</td>
<td>11676</td>
<td>8</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0002005018</td>
<td>Clara Callan</td>
<td>Richard Bruce Wright</td>
<td>2001</td>
<td>HarperFlamingo Canada</td>
<td>41385</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1031131</td>
<td>0440400988</td>
<td>There's a Bat in Bunk Five</td>
<td>Paula Danziger</td>
<td>1988</td>
<td>Random House Childrens Pub (Mm)</td>
<td>276463</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1031132</td>
<td>0525447644</td>
<td>From One to One Hundred</td>
<td>Teri Sloat</td>
<td>1991</td>
<td>Dutton Books</td>
<td>276579</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1031133</td>
<td>006008667X</td>
<td>Lily Dale : The True Story of the Town that Ta...</td>
<td>Christine Wicker</td>
<td>2004</td>
<td>HarperSanFrancisco</td>
<td>276680</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1031134</td>
<td>0192126040</td>
<td>Republic (World's Classics)</td>
<td>Plato</td>
<td>1996</td>
<td>Oxford University Press</td>
<td>276680</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1031135</td>
<td>0767409752</td>
<td>A Guided Tour of Rene Descartes' Meditations o...</td>
<td>Christopher Biffle</td>
<td>2000</td>
<td>McGraw-Hill Humanities/Social Sciences/Languages</td>
<td>276680</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>1031136 rows × 7 columns</p>
</div>
</div>
</div>
<p>Additionally, before handing my combined Book dataset over for Machine Learning training and prediction, I need to clean the data prior to the analysis stage: removing duplicates, deleting null/NaN vales, fixing types of columns, filling invalid values with suitable alternatives, etc. Fortunately, the data inherited from Kaggle here is in a preferable format already, so there does not need to be extensive amount of data cleaning here.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Figuring out the number of duplicated elements in the dataset (could be </span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># problematic if not resolved)</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>df.duplicated().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Figuring out the number of 'null'/'NaN' elements in the dataset (if NaN </span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># filling is needed or not)</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>(df.isnull().<span class="bu">sum</span>() <span class="op">/</span> df.shape[<span class="dv">0</span>]) <span class="op">*</span> <span class="dv">100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>ISBN                   0.000000
Book-Title             0.000000
Book-Author            0.000097
Year-Of-Publication    0.000000
Publisher              0.000194
User-ID                0.000000
Book-Rating            0.000000
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill unknown and unformatted values with proper ones for readability and to</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># improve data accuracy and relevance </span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"Book-Author"</span>].fillna(<span class="st">"N/A"</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"Publisher"</span>].fillna(<span class="st">"N/A"</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"Year-Of-Publication"</span>] <span class="op">=</span> df[<span class="st">"Year-Of-Publication"</span>].astype(<span class="bu">str</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"Year-Of-Publication"</span>] <span class="op">=</span> df[<span class="st">"Year-Of-Publication"</span>].<span class="bu">map</span>(<span class="kw">lambda</span> entry: entry <span class="cf">if</span> entry.isnumeric() <span class="cf">else</span> df[<span class="st">"Year-Of-Publication"</span>].mode()[<span class="dv">0</span>])</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"Year-Of-Publication"</span>] <span class="op">=</span> df[<span class="st">"Year-Of-Publication"</span>].astype(<span class="st">"int64"</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Change types of columns to allow an easier time to parse</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"Book-Title"</span>] <span class="op">=</span> df[<span class="st">"Book-Title"</span>].astype(<span class="bu">str</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"Book-Author"</span>] <span class="op">=</span> df[<span class="st">"Book-Author"</span>].astype(<span class="bu">str</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"ISBN"</span>] <span class="op">=</span> df[<span class="st">"ISBN"</span>].astype(<span class="bu">str</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"Publisher"</span>] <span class="op">=</span> df[<span class="st">"Publisher"</span>].astype(<span class="bu">str</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Getting basic information about the dataset (once again)</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 1031136 entries, 0 to 1031135
Data columns (total 7 columns):
 #   Column               Non-Null Count    Dtype 
---  ------               --------------    ----- 
 0   ISBN                 1031136 non-null  object
 1   Book-Title           1031136 non-null  object
 2   Book-Author          1031136 non-null  object
 3   Year-Of-Publication  1031136 non-null  int64 
 4   Publisher            1031136 non-null  object
 5   User-ID              1031136 non-null  int64 
 6   Book-Rating          1031136 non-null  int64 
dtypes: int64(3), object(4)
memory usage: 62.9+ MB</code></pre>
</div>
</div>
<p>As defined in the code snippet below, with subsequent modifications and copies of the working dataset, there will be a need to quantify the status and real-life/applicable statistics out to you, the user. Thus, I designed a function to report needed information called <code>report_basic_stats</code>. From time to time, there will be calls to this function, giving up-to-date information about the state of the dataset currently modified.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> report_basic_stats(dataframe: pd.DataFrame, <span class="bu">type</span>: <span class="bu">str</span>):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> n_users, n_books</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    n_users <span class="op">=</span> dataframe[<span class="st">"User-ID"</span>].unique().shape[<span class="dv">0</span>]</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    n_books <span class="op">=</span> dataframe[<span class="st">"ISBN"</span>].unique().shape[<span class="dv">0</span>]</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    n_ratings <span class="op">=</span> <span class="bu">len</span>(dataframe[<span class="st">"Book-Rating"</span>])</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    avg_num_ratings_per_user <span class="op">=</span> n_ratings <span class="op">/</span> n_users</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Number of Unique Book Users in This Dataset (</span><span class="sc">{}</span><span class="st">):"</span>.<span class="bu">format</span>(<span class="bu">type</span>), n_users)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Number of Unique Book Titles / ISBNs in This Dataset (</span><span class="sc">{}</span><span class="st">):"</span>.<span class="bu">format</span>(<span class="bu">type</span>), n_books)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Number of Total Ratings in This Dataset (</span><span class="sc">{}</span><span class="st">):"</span>.<span class="bu">format</span>(<span class="bu">type</span>), n_ratings)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Average Number of Book Ratings per User in This Dataset (</span><span class="sc">{}</span><span class="st">):"</span>.<span class="bu">format</span>(<span class="bu">type</span>), <span class="bu">round</span>(avg_num_ratings_per_user, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Alright, let’s begin by looking at the up-to-date information about the state of the original dataset using the <code>report_basic_stats</code> function:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>report_basic_stats(df, <span class="st">"Regular"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of Unique Book Users in This Dataset (Regular): 92106
Number of Unique Book Titles / ISBNs in This Dataset (Regular): 270151
Number of Total Ratings in This Dataset (Regular): 1031136
Average Number of Book Ratings per User in This Dataset (Regular): 11.195</code></pre>
</div>
</div>
<p>At this point, the data has been cleaned. However, there are some modifications that I have considered in this case such as limiting the amount of Book-ISBNs and Book-Users displayed (up to 3000 in this case). This is intentional to keep the dataset from becoming too long to visualize and compute within the Machine Learning model.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter the first 3000 Book-ISBNs in Dataset</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>book_isbn_index <span class="op">=</span> df.groupby(<span class="st">"ISBN"</span>).count().sort_values(by<span class="op">=</span><span class="st">"Book-Rating"</span>, ascending<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>:<span class="dv">3000</span>].index</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df[df[<span class="st">"ISBN"</span>].isin(book_isbn_index)]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>df2.count()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>ISBN                   271456
Book-Title             271456
Book-Author            271456
Year-Of-Publication    271456
Publisher              271456
User-ID                271456
Book-Rating            271456
dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter the first 3000 Book-Users in Dataset</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>book_users_index <span class="op">=</span> df2.groupby(<span class="st">"User-ID"</span>).count().sort_values(by<span class="op">=</span><span class="st">"Book-Rating"</span>, ascending<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>:<span class="dv">3000</span>].index</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> df2[df2[<span class="st">"User-ID"</span>].isin(book_users_index)]</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>df3.count()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>ISBN                   172071
Book-Title             172071
Book-Author            172071
Year-Of-Publication    172071
Publisher              172071
User-ID                172071
Book-Rating            172071
dtype: int64</code></pre>
</div>
</div>
<p>Since I had to cut down to 3000 Book-entries maximum in the dataset, I had to reindex the unique Book-ISBNs and Book User-IDs to account for this filtering. Thus, I removed all entries that were not part of this subset to maintain data consistency and integrity.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a separate dataframe for unique Book-ISBNs</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>book_isbns <span class="op">=</span> df3[<span class="st">"ISBN"</span>].unique()</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>isbn_df <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>book_isbns, columns<span class="op">=</span>[<span class="st">"Original-ISBN"</span>])</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>isbn_df[<span class="st">"New-ISBN"</span>] <span class="op">=</span> isbn_df.index <span class="op">+</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a separate dataframe for unique Book-Users (indicated by their IDs)</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>book_users <span class="op">=</span> df3[<span class="st">"User-ID"</span>].unique()</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>users_df <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>book_users, columns<span class="op">=</span>[<span class="st">"Original-User-ID"</span>])</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>users_df[<span class="st">"New-User-ID"</span>] <span class="op">=</span> users_df.index <span class="op">+</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge in new indices for Book-ISBN and Book-User-IDs that are modified</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># from 1 to 3000 (accounts for scaling down of data)</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>cleaned_df <span class="op">=</span> df3.merge(isbn_df, left_on<span class="op">=</span><span class="st">"ISBN"</span>, right_on<span class="op">=</span><span class="st">"Original-ISBN"</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>cleaned_df.drop(columns<span class="op">=</span>[<span class="st">"Original-ISBN"</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>cleaned_df <span class="op">=</span> cleaned_df.merge(users_df, left_on<span class="op">=</span><span class="st">"User-ID"</span>, right_on<span class="op">=</span><span class="st">"Original-User-ID"</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>cleaned_df.drop(columns<span class="op">=</span>[<span class="st">"Original-User-ID"</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>cleaned_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ISBN</th>
<th data-quarto-table-cell-role="th">Book-Title</th>
<th data-quarto-table-cell-role="th">Book-Author</th>
<th data-quarto-table-cell-role="th">Year-Of-Publication</th>
<th data-quarto-table-cell-role="th">Publisher</th>
<th data-quarto-table-cell-role="th">User-ID</th>
<th data-quarto-table-cell-role="th">Book-Rating</th>
<th data-quarto-table-cell-role="th">New-ISBN</th>
<th data-quarto-table-cell-role="th">New-User-ID</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0440234743</td>
<td>The Testament</td>
<td>John Grisham</td>
<td>1999</td>
<td>Dell</td>
<td>277478</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0971880107</td>
<td>Wild Animus</td>
<td>Rich Shapero</td>
<td>2004</td>
<td>Too Far</td>
<td>277478</td>
<td>0</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0671888587</td>
<td>I'll Be Seeing You</td>
<td>Mary Higgins Clark</td>
<td>1994</td>
<td>Pocket</td>
<td>277478</td>
<td>0</td>
<td>9</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0440225701</td>
<td>The Street Lawyer</td>
<td>JOHN GRISHAM</td>
<td>1999</td>
<td>Dell</td>
<td>277478</td>
<td>0</td>
<td>15</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0786868716</td>
<td>The Five People You Meet in Heaven</td>
<td>Mitch Albom</td>
<td>2003</td>
<td>Hyperion</td>
<td>277478</td>
<td>0</td>
<td>30</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">172066</td>
<td>0767908171</td>
<td>A Short History of Nearly Everything</td>
<td>Bill Bryson</td>
<td>2003</td>
<td>Broadway</td>
<td>70999</td>
<td>0</td>
<td>2798</td>
<td>3000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">172067</td>
<td>0385234104</td>
<td>Fatherhood</td>
<td>Bill Cosby</td>
<td>1986</td>
<td>Bantam Dell Pub Group</td>
<td>70999</td>
<td>0</td>
<td>2857</td>
<td>3000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">172068</td>
<td>0425190641</td>
<td>Fire Ice: A Novel from the Numa Files (Kurt Au...</td>
<td>Clive Cussler</td>
<td>2003</td>
<td>Berkley Publishing Group</td>
<td>70999</td>
<td>0</td>
<td>2874</td>
<td>3000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">172069</td>
<td>0553584375</td>
<td>No One to Trust</td>
<td>IRIS JOHANSEN</td>
<td>2003</td>
<td>Bantam</td>
<td>70999</td>
<td>0</td>
<td>2880</td>
<td>3000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">172070</td>
<td>044023512X</td>
<td>City of Light</td>
<td>Lauren Belfer</td>
<td>2000</td>
<td>Island</td>
<td>70999</td>
<td>0</td>
<td>2941</td>
<td>3000</td>
</tr>
</tbody>
</table>

<p>172071 rows × 9 columns</p>
</div>
</div>
</div>
<p>Here, I am trying to offer some visualizations of the cleaned dataset before we pass it over for Machine Learning training and prediction. The first visualization (below) describes about the total number of reviews given to each of the 3000 books in the dataset. Arbitrarily though, I set a maximum of 30 book titles visualized to save space as my editor could not plot more than that without it become illegible. The strategy there was grouping by Book-Titles and and counting number of Book-Rating entries for that particular Book entry.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a copy of the cleaned dataframe</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>cleaned_df_condensed_trends <span class="op">=</span> cleaned_df.copy()</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop unnecessary columns</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>cleaned_df_condensed_trends.drop(labels<span class="op">=</span>[<span class="st">"ISBN"</span>, </span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>                                         <span class="st">"Book-Author"</span>,</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>                                         <span class="st">"Year-Of-Publication"</span>,</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>                                         <span class="st">"Publisher"</span>,</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>                                         <span class="st">"User-ID"</span>,</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>                                         <span class="st">"New-ISBN"</span>,</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>                                         <span class="st">"New-User-ID"</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Used grouping and counting to gather book-review counts for each indexed title</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>cleaned_df_condensed_trends_copy <span class="op">=</span> cleaned_df_condensed_trends.copy()</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>cleaned_df_condensed_trends <span class="op">=</span> pd.DataFrame(cleaned_df_condensed_trends_copy</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>                                           .groupby(<span class="st">"Book-Title"</span>)[<span class="st">"Book-Rating"</span>]</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>                                           .mean())</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>cleaned_df_condensed_trends[<span class="st">"Total-Num-Of-Ratings"</span>] <span class="op">=</span> pd.DataFrame(cleaned_df_condensed_trends_copy</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>                                                                   .groupby(<span class="st">"Book-Title"</span>)[<span class="st">"Book-Rating"</span>]</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>                                                                   .count())</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>cleaned_df_condensed_trends.head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Book-Rating</th>
<th data-quarto-table-cell-role="th">Total-Num-Of-Ratings</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">Book-Title</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">10 Lb. Penalty</td>
<td>1.911765</td>
<td>34</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">16 Lighthouse Road</td>
<td>1.276596</td>
<td>47</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1984</td>
<td>3.817460</td>
<td>126</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1st to Die: A Novel</td>
<td>2.893891</td>
<td>311</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2010: Odyssey Two</td>
<td>2.086207</td>
<td>58</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">204 Rosewood Lane</td>
<td>1.581818</td>
<td>55</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2061: Odyssey Three</td>
<td>3.133333</td>
<td>30</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">24 Hours</td>
<td>1.454545</td>
<td>44</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2nd Chance</td>
<td>2.704167</td>
<td>240</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">311 Pelican Court</td>
<td>2.435897</td>
<td>39</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating a bar graph describing number of reviews for first 30 books</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>ax<span class="op">=</span>plt.subplot()</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>ax.bar(cleaned_df_condensed_trends.head(<span class="dv">30</span>).index,</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>       cleaned_df_condensed_trends[<span class="st">"Total-Num-Of-Ratings"</span>].head(<span class="dv">30</span>), </span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>       color<span class="op">=</span><span class="st">"b"</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels(cleaned_df_condensed_trends.index,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>                   rotation<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>                   fontsize<span class="op">=</span><span class="st">"12"</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>                   horizontalalignment<span class="op">=</span><span class="st">"right"</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Total Number of Reviews For Each Book"</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\andre\AppData\Local\Temp\ipykernel_7880\177655821.py:7: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(cleaned_df_condensed_trends.index,</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-23-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Just to give an interesting statistic, I decided to make another copy of the working dataset, grouped by Book-Title but sorted by Book-Rating. This was intentional to output and report the most-popular (Top-50 rated books) and least-populat (Bottom-50 rated books) on average, which is an important piece of data for the user to know.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean rating of all books</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Output the Top-50 and Bottom-50 rated books on average</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>cleaned_df_sorted_mean_rating <span class="op">=</span> cleaned_df.copy().groupby(<span class="st">"Book-Title"</span>)[<span class="st">"Book-Rating"</span>].mean().sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--------- Sorted by Mean On Average: ---------</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--------- TOP 50: ---------</span><span class="ch">\n</span><span class="st">"</span>, cleaned_df_sorted_mean_rating.head(<span class="dv">50</span>))</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">--------- BOTTOM 50: ---------</span><span class="ch">\n</span><span class="st">"</span>, cleaned_df_sorted_mean_rating.tail(<span class="dv">50</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--------- Sorted by Mean On Average: ---------

--------- TOP 50: ---------
 Book-Title
Generation Golf. Eine Inspektion                                                                          9.000000
Novocento, Un Monologo                                                                                    9.000000
Io Non Ho Paura                                                                                           8.000000
Herr Lehmann.                                                                                             7.500000
L'Etranger (Collection Folio, 2)                                                                          6.777778
Griffin &amp;amp; Sabine: An Extraordinary Correspondence                                                     6.000000
The Darwin Awards: Evolution in Action                                                                    5.653846
Harry Potter and the Sorcerer's Stone (Book 1)                                                            5.651613
My Sister's Keeper : A Novel (Picoult, Jodi)                                                              5.515152
Harry Potter and the Prisoner of Azkaban (Book 3)                                                         5.465116
Harry Potter and the Goblet of Fire (Book 4)                                                              5.445415
The Stand (The Complete and Uncut Edition)                                                                5.433333
Balzac and the Little Chinese Seamstress                                                                  5.379310
Harry Potter and the Chamber of Secrets Postcard Book                                                     5.363636
The Lone Ranger and Tonto Fistfight in Heaven                                                             5.333333
Harry Potter and the Order of the Phoenix (Book 5)                                                        5.277228
Hamlet                                                                                                    5.241379
The Lunatic Cafe (Anita Blake Vampire Hunter (Paperback))                                                 5.230769
The Little Prince                                                                                         5.210526
Wiener Dog Art                                                                                            5.157895
Weirdos From Another Planet!                                                                              5.147059
Killing Dance (Anita Blake Vampire Hunter (Paperback))                                                    5.142857
The Secret Garden                                                                                         5.133333
Wicca: A Guide for the Solitary Practitioner                                                              5.120000
Sabine's Notebook: In Which the Extraordinary Correspondence of Griffin &amp;amp; Sabine Continues            5.105263
The Metamorphosis (Bantam Classics)                                                                       5.062500
The Grapes of Wrath (20th Century Classics)                                                               5.031250
The Lion, the Witch, and the Wardrobe (The Chronicles of Narnia, Book 2)                                  4.978723
Green Eggs and Ham (I Can Read It All by Myself Beginner Books)                                           4.931034
Harry Potter and the Chamber of Secrets (Book 2)                                                          4.924092
The Cat in the Hat                                                                                        4.903226
GREAT GATSBY (REISSUE)                                                                                    4.800000
Ender's Game (Ender Wiggins Saga (Paperback))                                                             4.793478
The Vagina Monologues: The V-Day Edition                                                                  4.793103
The Godfather                                                                                             4.783784
All I Need to Know I Learned from My Cat                                                                  4.769231
Hyperion                                                                                                  4.764706
Sister of My Heart                                                                                        4.743590
Sense and Sensibility (Penguin Popular Classics)                                                          4.733333
On the Banks of Plum Creek                                                                                4.718750
Rich Dad, Poor Dad: What the Rich Teach Their Kids About Money--That the Poor and Middle Class Do Not!    4.717949
The Lord of the Rings (Movie Art Cover)                                                                   4.714286
Needful Things: The Last Castle Rock Story                                                                4.681818
The Jungle (Bantam Classics)                                                                              4.652174
Memoirs of a Geisha                                                                                       4.638298
Pride &amp;amp; Prejudice (Wordsworth Classics)                                                               4.631579
The Spirit Catches You and You Fall Down                                                                  4.600000
Anthem                                                                                                    4.590909
JITTERBUG PERFUME                                                                                         4.571429
The Curious Incident of the Dog in the Night-Time (Vintage Contemporaries)                                4.571429
Name: Book-Rating, dtype: float64


--------- BOTTOM 50: ---------
 Book-Title
Silent Honor                                                                                                               0.735294
Vernon God Little: A 21st Century Comedy in the Presence of Death                                                          0.727273
Ruthless.Com (Tom Clancy's Power Plays (Paperback))                                                                        0.725806
The Blooding                                                                                                               0.722222
Where You Belong                                                                                                           0.720930
The Matarese Countdown                                                                                                     0.717949
Pleading Guilty                                                                                                            0.716049
Family Pictures                                                                                                            0.714286
Fortune's Hand                                                                                                             0.708333
Passion's Promise                                                                                                          0.705882
Ssn                                                                                                                        0.700000
The Icarus Agenda                                                                                                          0.700000
Legacy of Silence                                                                                                          0.696970
Confessions of a Sociopathic Social Climber : The Katya Livingston Chronicles (Katya Livingston Chronicles (Hardcover))    0.695652
The Blue Last: A Richard Jury Mystery (Richard Jury Mysteries (Paperback))                                                 0.695652
Subterranean                                                                                                               0.695652
The Legend of Bagger Vance                                                                                                 0.692308
State of Siege (Tom Clancy's Op-Center, 6)                                                                                 0.680851
Man From St Petersburg                                                                                                     0.659091
Master of the Game                                                                                                         0.658537
Rosehaven                                                                                                                  0.656250
The X-Files: Goblins                                                                                                       0.640000
Welcome to Dead House (Goosebumps, No 1)                                                                                   0.638889
Ground Zero and Beyond                                                                                                     0.629032
Los Alamos: A Novel                                                                                                        0.620690
Treasures                                                                                                                  0.617647
Whirlwind                                                                                                                  0.606061
If Tomorrow Comes                                                                                                          0.605263
WEB OF DREAMS (Casteel Saga (Paperback))                                                                                   0.604651
Starting Over                                                                                                              0.600000
Hurricane Bay                                                                                                              0.600000
Montana                                                                                                                    0.595238
Wild Animus                                                                                                                0.582865
People of the River (The First North Americans series, Book 4)                                                             0.571429
Honor Among Thieves                                                                                                        0.568182
The Cat Who Went into the Closet                                                                                           0.566038
After the Fire                                                                                                             0.564103
Yesterday                                                                                                                  0.531250
Monster Blood (Goosebumps, No 3)                                                                                           0.466667
Women in His Life                                                                                                          0.452381
Long, Lean, and Lethal                                                                                                     0.451613
Dating Game                                                                                                                0.400000
Billy Straight: A Novel                                                                                                    0.375000
McNally's Luck (Archy McNally Novels (Paperback))                                                                          0.365854
Final Flight                                                                                                               0.333333
Stay Out of the Basement (Goosebumps, No 2)                                                                                0.285714
Say Cheese and Die! (Goosebumps, No 4)                                                                                     0.275862
Long Time No See                                                                                                           0.161290
The Sculptress                                                                                                             0.000000
Der Vorleser                                                                                                               0.000000
Name: Book-Rating, dtype: float64</code></pre>
</div>
</div>
<p>The second visualization gathers all of the numerical book-ratings across all books, contrasting how book reviewers score and evaluate these literature text sources generally. With this ranged data, it would seem most appropriate to display this visualization of statistical data within a histogram.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>sns.histplot(pd.DataFrame(cleaned_df_sorted_mean_rating)[<span class="st">"Book-Rating"</span>], color<span class="op">=</span><span class="st">"r"</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Histogram - Distribution of Book-Ratings Across All Books in the Dataset"</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>As compared to earlier, let’s look at the up-to-date information about the state of the reduced (in-size) dataset using the <code>report_basic_stats</code> function.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>report_basic_stats(cleaned_df, <span class="st">"Reduced"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of Unique Book Users in This Dataset (Reduced): 3000
Number of Unique Book Titles / ISBNs in This Dataset (Reduced): 3000
Number of Total Ratings in This Dataset (Reduced): 172071
Average Number of Book Ratings per User in This Dataset (Reduced): 57.357</code></pre>
</div>
</div>
</section>
<section id="machine-learning---model-training-and-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning---model-training-and-evaluation">Machine Learning - Model Training and Evaluation</h2>
<p>Great, now we are onto the Machine Learning part of the blog post!</p>
<p>Since the dataframe is now properly cleaned by this point, I had split the respective dataframe into the train, test, and validation datasets for the Machine Learning model with 90% going to the training dataset, the next 5% going to the validation dataset, and the last 5% going to the test dataset. Fortunately, because order of the data sequentially does not matter here, I was able to utilize the <code>train_test_split</code> function for shuffling and randomization, making the future-generated Machine Learning model more unpredictable but also more objective in its returned model results.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuring the Machine Learning Tensorflow Model by splitting the data 90% for testing,</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 5% for validation, and 5% for testing</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> train_test_split(cleaned_df, test_size<span class="op">=</span><span class="fl">0.10</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">2018</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>X_val, X_test <span class="op">=</span> train_test_split(X_test, test_size<span class="op">=</span><span class="fl">0.50</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">2018</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Outputting the shape of the new datasets</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of Training Set:"</span>, X_train.shape, <span class="st">"and Size of Training Set:"</span>, X_train.size)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of Validation Set:"</span>, X_val.shape, <span class="st">"and Size of Validation Set:"</span>, X_val.size)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Shape of Test Set:"</span>, X_test.shape, <span class="st">"and Size of Testing Set:"</span>, X_test.size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of Training Set: (154863, 9) and Size of Training Set: 1393767
Shape of Validation Set: (8604, 9) and Size of Validation Set: 77436
Shape of Test Set: (8604, 9) and Size of Testing Set: 77436</code></pre>
</div>
</div>
<p>As recommended online for any Collaborative-Filtering Recommendation Systems, one suggestion was to manually check and compute the <code>mean_squared_error</code> for ratings in your dataset. Thus, I defined a cost function that utilizes a sparse <code>np.array</code> starting with all 0’s of dimension-size <code>n_users x n_books</code>. The entries at specified locations would be converted non-zero by utilizing every Book-ISBN and Book User-ID position to generate a computed rating. The objective with calculating the <code>mean_squared_error</code> is to check how close estimates are to actual, observed values found within the given dataset.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define my cost function (mean-squared error) for each dataset before the</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co"># invokation of the Machine Learning algorithm</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>df_ratings_train <span class="op">=</span> np.zeros((n_users, n_books))</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> r <span class="kw">in</span> X_train.itertuples():</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    df_ratings_train[r[<span class="dv">9</span>] <span class="op">-</span> <span class="dv">1</span>, r[<span class="dv">8</span>] <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> r[<span class="dv">7</span>]</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_ratings_train.shape)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>df_ratings_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(3000, 3000)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>df_ratings_validation <span class="op">=</span> np.zeros((n_users, n_books))</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> r <span class="kw">in</span> X_val.itertuples():</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    df_ratings_validation[r[<span class="dv">9</span>] <span class="op">-</span> <span class="dv">1</span>, r[<span class="dv">8</span>] <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> r[<span class="dv">7</span>]</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_ratings_validation.shape)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>df_ratings_validation</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(3000, 3000)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>df_ratings_test <span class="op">=</span> np.zeros((n_users, n_books))</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> r <span class="kw">in</span> X_test.itertuples():</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    df_ratings_test[r[<span class="dv">9</span>] <span class="op">-</span> <span class="dv">1</span>, r[<span class="dv">8</span>] <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> r[<span class="dv">7</span>]</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_ratings_test.shape)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>df_ratings_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(3000, 3000)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])</code></pre>
</div>
</div>
<p>After the dataframes had the cost function computed for all, I made 2 matrices - one for the book user-similiarity and one for the book item-similarity. The idea here is to account for relative difference in the ratings between several distinct Book-Users and Book-ISBNs (items) themselves. Statically proven, relative differences in ratings give more insight than the absolute rating values. As described on the CambridgeSpark reference below, the rating system could be skewed by human biases such as solid consistent ratings for good vs.&nbsp;bad books through cover inspection, ratings based on topic preference or thoughts on the user’s views rather than objective review, etc.</p>
<p>Note that in the user-based similarity predictions that ratings as weights need to be normalized, so summation and average on top of a dot-product calcuation on the matrix is needed. This is to make sure the ratings stay within the expected range of 1.0 (worst) to 10.0 (best).</p>
<p>At the end of the code cell below, a comparison on the prediction matrices with the <code>df_ratings_test</code> matrix using dimensionality reduction and the <code>mean_squared_error</code> function the <code>sklearn.metrics</code> module is computed to quantify the closeness of estimates to the actual dataset (as described previously).</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>book_user_similarity <span class="op">=</span> pairwise_distances(df_ratings_train, metric<span class="op">=</span><span class="st">"cosine"</span>)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>book_item_similarity <span class="op">=</span> pairwise_distances(df_ratings_train.T, metric<span class="op">=</span><span class="st">"cosine"</span>)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> perform_prediction_similarity_based(ratings, similiarity, pred_type<span class="op">=</span><span class="st">"user"</span>):</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pred_type <span class="op">==</span> <span class="st">"user"</span>:</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>        mean_user_rating <span class="op">=</span> ratings.mean(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># You use np.newaxis so that the user_rating has the same format as ratings</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>        ratings_diff <span class="op">=</span> (ratings <span class="op">-</span> mean_user_rating[: np.newaxis])</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> mean_user_rating[: np.newaxis] <span class="op">+</span> (similiarity.dot(ratings_diff) <span class="op">/</span> np.array([np.<span class="bu">abs</span>(similiarity).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)]))</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> pred_type <span class="op">==</span> <span class="st">"item"</span>:</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> ratings.dot(similiarity) <span class="op">/</span> np.array([np.<span class="bu">abs</span>(similiarity).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)])</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>book_user_prediction <span class="op">=</span> perform_prediction_similarity_based(df_ratings_train, book_user_similarity, pred_type<span class="op">=</span><span class="st">"user"</span>)</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>book_item_prediction <span class="op">=</span> perform_prediction_similarity_based(df_ratings_train, book_item_similarity, pred_type<span class="op">=</span><span class="st">"item"</span>)</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_mean_square_error(predicted, actual):</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>    predicted <span class="op">=</span> predicted[actual.nonzero()].flatten()</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>    actual <span class="op">=</span> actual[actual.nonzero()].flatten()</span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mean_squared_error(predicted, actual)</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"For Collaborative Filtering:"</span>)</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Book User-Based Mean-Square-Error: </span><span class="sc">{</span>compute_mean_square_error(book_user_prediction, df_ratings_test)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Book Item-Based Mean-Square-Error: </span><span class="sc">{</span>compute_mean_square_error(book_item_prediction, df_ratings_test)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>For Collaborative Filtering:
Book User-Based Mean-Square-Error: 63.272539998623145
Book Item-Based Mean-Square-Error: 62.53832448961992</code></pre>
</div>
</div>
<p>One other calculation that is beneficial to check with regards to these matrices includes matrix sparsity. With a less sparse matrix (through a lower-percentage return), I found that it was more beneficial to more efficient to use dense Machine Learning representations and algorithms optimized for dense data, which will done later while creating the Sequential layering of the model. After performing the calculations below, this seemed to be the case I was dealing with here.</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_sparsity_stats(df: pd.DataFrame, <span class="bu">type</span>: <span class="bu">str</span>):</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-------------- Sparsity Stats for </span><span class="sc">{}</span><span class="st">: --------------"</span>.<span class="bu">format</span>(<span class="bu">type</span>))</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    df_sparsity <span class="op">=</span> <span class="bu">float</span>(<span class="bu">len</span>(df.nonzero()[<span class="dv">0</span>]))</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    df_sparsity <span class="op">/=</span> (df.shape[<span class="dv">0</span>] <span class="op">*</span> df.shape[<span class="dv">1</span>])</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    df_sparsity <span class="op">*=</span> <span class="dv">100</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Sparsity: </span><span class="sc">{:4.2f}</span><span class="st">%'</span>.<span class="bu">format</span>(df_sparsity))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>print_sparsity_stats(df_ratings_train, <span class="st">"Train"</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>print_sparsity_stats(df_ratings_validation, <span class="st">"Validation"</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>print_sparsity_stats(df_ratings_test, <span class="st">"Test"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-------------- Sparsity Stats for Train: --------------
Sparsity: 0.53%
-------------- Sparsity Stats for Validation: --------------
Sparsity: 0.03%
-------------- Sparsity Stats for Test: --------------
Sparsity: 0.03%</code></pre>
</div>
</div>
<p>Now, I began to configure the Machine Learning model. We added Sequential layers of Input: incorporated an Input layer 1 by 1 because I only had 1 <code>np.array</code> as Input for Book-Users and another one as Input for Book-Items themselves, utilize a Embedding as recommended for each of the Input layers for models like these, and I followed up with flattening for dimensionality-reduction of both embeddings with input. Combining it with the dot-product of the two vector embeddings with input to make the initial model, we compiled it, utilzing the <code>mean_square_error</code> as our minimizing loss function, using the <code>Adam</code> optimizer, and comparing our trained model against our data with the <code>mean_absolute_error</code> metric. Lastly, I fitted our model, utilzing both of our X_train datasets and the Y_train dataset for fitting with validation from both of our X_val datasets and the Y_val dataset at 100 epochs.</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the Input, Embeddings, and Dot Product on the Model</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>n_latent_fact <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>user_input <span class="op">=</span> Input(shape<span class="op">=</span>[<span class="dv">1</span>], name<span class="op">=</span><span class="st">"User"</span>)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>user_embedding <span class="op">=</span> Embedding(input_dim<span class="op">=</span>n_users <span class="op">+</span> <span class="dv">1</span>, </span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>                           output_dim<span class="op">=</span>n_latent_fact, </span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>                           name<span class="op">=</span><span class="st">"User_Embedding"</span>)(user_input)</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>user_vec <span class="op">=</span> Flatten(name<span class="op">=</span><span class="st">"Flatten_Users"</span>)(user_embedding)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>book_input <span class="op">=</span> Input(shape<span class="op">=</span>[<span class="dv">1</span>], name<span class="op">=</span><span class="st">"Book"</span>)</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>book_embedding <span class="op">=</span> Embedding(input_dim<span class="op">=</span>n_books <span class="op">+</span> <span class="dv">1</span>, </span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>                           output_dim<span class="op">=</span>n_latent_fact, </span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>                           name<span class="op">=</span><span class="st">"Book_Embedding"</span>)(book_input)</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>book_vec <span class="op">=</span> Flatten(name<span class="op">=</span><span class="st">"Flatten_Movies"</span>)(book_embedding)</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>dot_product <span class="op">=</span> dot([book_vec, user_vec], axes<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(inputs<span class="op">=</span>[user_input, book_input], outputs<span class="op">=</span>dot_product)</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the model and fit the datasets to it</span></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"mse"</span>,</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>              optimizer<span class="op">=</span>Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>),</span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">"mean_absolute_error"</span>])</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>book_rec_history <span class="op">=</span> model.fit(x<span class="op">=</span>(X_train[<span class="st">"New-User-ID"</span>], X_train[<span class="st">"New-ISBN"</span>]), </span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>                             y<span class="op">=</span>X_train[<span class="st">"Book-Rating"</span>],</span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>                             epochs<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>                             validation_data<span class="op">=</span>([X_val[<span class="st">"New-User-ID"</span>], X_val[<span class="st">"New-ISBN"</span>]], X_val[<span class="st">"Book-Rating"</span>]),</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>                             use_multiprocessing<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/100
4840/4840 [==============================] - 8s 1ms/step - loss: 19.9551 - mean_absolute_error: 2.4209 - val_loss: 19.6552 - val_mean_absolute_error: 2.4027
Epoch 2/100
4840/4840 [==============================] - 6s 1ms/step - loss: 19.3750 - mean_absolute_error: 2.4419 - val_loss: 18.6760 - val_mean_absolute_error: 2.4445
Epoch 3/100
4840/4840 [==============================] - 6s 1ms/step - loss: 18.1293 - mean_absolute_error: 2.4874 - val_loss: 17.3686 - val_mean_absolute_error: 2.5010
Epoch 4/100
4840/4840 [==============================] - 6s 1ms/step - loss: 16.7393 - mean_absolute_error: 2.5333 - val_loss: 16.1366 - val_mean_absolute_error: 2.5539
Epoch 5/100
4840/4840 [==============================] - 6s 1ms/step - loss: 15.4796 - mean_absolute_error: 2.5681 - val_loss: 15.1081 - val_mean_absolute_error: 2.5938
Epoch 6/100
4840/4840 [==============================] - 6s 1ms/step - loss: 14.4270 - mean_absolute_error: 2.5851 - val_loss: 14.2828 - val_mean_absolute_error: 2.6190
Epoch 7/100
4840/4840 [==============================] - 6s 1ms/step - loss: 13.5713 - mean_absolute_error: 2.5904 - val_loss: 13.6287 - val_mean_absolute_error: 2.6315
Epoch 8/100
4840/4840 [==============================] - 6s 1ms/step - loss: 12.8907 - mean_absolute_error: 2.5865 - val_loss: 13.1184 - val_mean_absolute_error: 2.6345
Epoch 9/100
4840/4840 [==============================] - 6s 1ms/step - loss: 12.3554 - mean_absolute_error: 2.5763 - val_loss: 12.7195 - val_mean_absolute_error: 2.6323
Epoch 10/100
4840/4840 [==============================] - 6s 1ms/step - loss: 11.9377 - mean_absolute_error: 2.5634 - val_loss: 12.4135 - val_mean_absolute_error: 2.6284
Epoch 11/100
4840/4840 [==============================] - 6s 1ms/step - loss: 11.6136 - mean_absolute_error: 2.5515 - val_loss: 12.1788 - val_mean_absolute_error: 2.6224
Epoch 12/100
4840/4840 [==============================] - 6s 1ms/step - loss: 11.3626 - mean_absolute_error: 2.5393 - val_loss: 11.9995 - val_mean_absolute_error: 2.6160
Epoch 13/100
4840/4840 [==============================] - 6s 1ms/step - loss: 11.1686 - mean_absolute_error: 2.5275 - val_loss: 11.8625 - val_mean_absolute_error: 2.6099
Epoch 14/100
4840/4840 [==============================] - 6s 1ms/step - loss: 11.0204 - mean_absolute_error: 2.5182 - val_loss: 11.7559 - val_mean_absolute_error: 2.6039
Epoch 15/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.9062 - mean_absolute_error: 2.5079 - val_loss: 11.6769 - val_mean_absolute_error: 2.5991
Epoch 16/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.8185 - mean_absolute_error: 2.5007 - val_loss: 11.6162 - val_mean_absolute_error: 2.5955
Epoch 17/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.7506 - mean_absolute_error: 2.4947 - val_loss: 11.5723 - val_mean_absolute_error: 2.5916
Epoch 18/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.6983 - mean_absolute_error: 2.4885 - val_loss: 11.5417 - val_mean_absolute_error: 2.5891
Epoch 19/100
4840/4840 [==============================] - 9s 2ms/step - loss: 10.6575 - mean_absolute_error: 2.4854 - val_loss: 11.5182 - val_mean_absolute_error: 2.5868
Epoch 20/100
4840/4840 [==============================] - 19s 4ms/step - loss: 10.6263 - mean_absolute_error: 2.4819 - val_loss: 11.5015 - val_mean_absolute_error: 2.5850
Epoch 21/100
4840/4840 [==============================] - 16s 3ms/step - loss: 10.6019 - mean_absolute_error: 2.4776 - val_loss: 11.4874 - val_mean_absolute_error: 2.5836
Epoch 22/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5823 - mean_absolute_error: 2.4753 - val_loss: 11.4817 - val_mean_absolute_error: 2.5837
Epoch 23/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5671 - mean_absolute_error: 2.4734 - val_loss: 11.4771 - val_mean_absolute_error: 2.5832
Epoch 24/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5551 - mean_absolute_error: 2.4724 - val_loss: 11.4728 - val_mean_absolute_error: 2.5824
Epoch 25/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5451 - mean_absolute_error: 2.4713 - val_loss: 11.4684 - val_mean_absolute_error: 2.5814
Epoch 26/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5374 - mean_absolute_error: 2.4702 - val_loss: 11.4669 - val_mean_absolute_error: 2.5806
Epoch 27/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5323 - mean_absolute_error: 2.4675 - val_loss: 11.4670 - val_mean_absolute_error: 2.5806
Epoch 28/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5271 - mean_absolute_error: 2.4674 - val_loss: 11.4662 - val_mean_absolute_error: 2.5810
Epoch 29/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5217 - mean_absolute_error: 2.4671 - val_loss: 11.4637 - val_mean_absolute_error: 2.5803
Epoch 30/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5194 - mean_absolute_error: 2.4657 - val_loss: 11.4639 - val_mean_absolute_error: 2.5808
Epoch 31/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5163 - mean_absolute_error: 2.4672 - val_loss: 11.4659 - val_mean_absolute_error: 2.5795
Epoch 32/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5140 - mean_absolute_error: 2.4651 - val_loss: 11.4672 - val_mean_absolute_error: 2.5803
Epoch 33/100
4840/4840 [==============================] - 15s 3ms/step - loss: 10.5122 - mean_absolute_error: 2.4647 - val_loss: 11.4685 - val_mean_absolute_error: 2.5801
Epoch 34/100
4840/4840 [==============================] - 18s 4ms/step - loss: 10.5110 - mean_absolute_error: 2.4642 - val_loss: 11.4730 - val_mean_absolute_error: 2.5809
Epoch 35/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5097 - mean_absolute_error: 2.4645 - val_loss: 11.4743 - val_mean_absolute_error: 2.5801
Epoch 36/100
4840/4840 [==============================] - 15s 3ms/step - loss: 10.5084 - mean_absolute_error: 2.4643 - val_loss: 11.4746 - val_mean_absolute_error: 2.5803
Epoch 37/100
4840/4840 [==============================] - 19s 4ms/step - loss: 10.5074 - mean_absolute_error: 2.4629 - val_loss: 11.4773 - val_mean_absolute_error: 2.5809
Epoch 38/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5066 - mean_absolute_error: 2.4635 - val_loss: 11.4802 - val_mean_absolute_error: 2.5813
Epoch 39/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5058 - mean_absolute_error: 2.4640 - val_loss: 11.4792 - val_mean_absolute_error: 2.5812
Epoch 40/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5065 - mean_absolute_error: 2.4626 - val_loss: 11.4789 - val_mean_absolute_error: 2.5808
Epoch 41/100
4840/4840 [==============================] - 8s 2ms/step - loss: 10.5048 - mean_absolute_error: 2.4639 - val_loss: 11.4800 - val_mean_absolute_error: 2.5809
Epoch 42/100
4840/4840 [==============================] - 7s 2ms/step - loss: 10.5050 - mean_absolute_error: 2.4628 - val_loss: 11.4804 - val_mean_absolute_error: 2.5809
Epoch 43/100
4840/4840 [==============================] - 15s 3ms/step - loss: 10.5049 - mean_absolute_error: 2.4619 - val_loss: 11.4816 - val_mean_absolute_error: 2.5811
Epoch 44/100
4840/4840 [==============================] - 14s 3ms/step - loss: 10.5038 - mean_absolute_error: 2.4628 - val_loss: 11.4815 - val_mean_absolute_error: 2.5808
Epoch 45/100
4840/4840 [==============================] - 15s 3ms/step - loss: 10.5042 - mean_absolute_error: 2.4624 - val_loss: 11.4844 - val_mean_absolute_error: 2.5816
Epoch 46/100
4840/4840 [==============================] - 14s 3ms/step - loss: 10.5038 - mean_absolute_error: 2.4626 - val_loss: 11.4859 - val_mean_absolute_error: 2.5817
Epoch 47/100
4840/4840 [==============================] - 9s 2ms/step - loss: 10.5040 - mean_absolute_error: 2.4633 - val_loss: 11.4860 - val_mean_absolute_error: 2.5803
Epoch 48/100
4840/4840 [==============================] - 13s 3ms/step - loss: 10.5043 - mean_absolute_error: 2.4611 - val_loss: 11.4846 - val_mean_absolute_error: 2.5803
Epoch 49/100
4840/4840 [==============================] - 8s 2ms/step - loss: 10.5034 - mean_absolute_error: 2.4620 - val_loss: 11.4822 - val_mean_absolute_error: 2.5801
Epoch 50/100
4840/4840 [==============================] - 12s 3ms/step - loss: 10.5036 - mean_absolute_error: 2.4621 - val_loss: 11.4911 - val_mean_absolute_error: 2.5819
Epoch 51/100
4840/4840 [==============================] - 5s 1ms/step - loss: 10.5024 - mean_absolute_error: 2.4628 - val_loss: 11.4901 - val_mean_absolute_error: 2.5813
Epoch 52/100
4840/4840 [==============================] - 8s 2ms/step - loss: 10.5030 - mean_absolute_error: 2.4617 - val_loss: 11.4920 - val_mean_absolute_error: 2.5820
Epoch 53/100
4840/4840 [==============================] - 7s 1ms/step - loss: 10.5031 - mean_absolute_error: 2.4616 - val_loss: 11.4928 - val_mean_absolute_error: 2.5822
Epoch 54/100
4840/4840 [==============================] - 8s 2ms/step - loss: 10.5028 - mean_absolute_error: 2.4633 - val_loss: 11.4911 - val_mean_absolute_error: 2.5807
Epoch 55/100
4840/4840 [==============================] - 9s 2ms/step - loss: 10.5038 - mean_absolute_error: 2.4608 - val_loss: 11.4946 - val_mean_absolute_error: 2.5813
Epoch 56/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5034 - mean_absolute_error: 2.4612 - val_loss: 11.4954 - val_mean_absolute_error: 2.5821
Epoch 57/100
4840/4840 [==============================] - 11s 2ms/step - loss: 10.5029 - mean_absolute_error: 2.4620 - val_loss: 11.4952 - val_mean_absolute_error: 2.5821
Epoch 58/100
4840/4840 [==============================] - 7s 2ms/step - loss: 10.5029 - mean_absolute_error: 2.4618 - val_loss: 11.4905 - val_mean_absolute_error: 2.5812
Epoch 59/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5029 - mean_absolute_error: 2.4620 - val_loss: 11.4908 - val_mean_absolute_error: 2.5813
Epoch 60/100
4840/4840 [==============================] - 7s 1ms/step - loss: 10.5033 - mean_absolute_error: 2.4617 - val_loss: 11.4942 - val_mean_absolute_error: 2.5807
Epoch 61/100
4840/4840 [==============================] - 7s 1ms/step - loss: 10.5032 - mean_absolute_error: 2.4614 - val_loss: 11.4948 - val_mean_absolute_error: 2.5805
Epoch 62/100
4840/4840 [==============================] - 7s 1ms/step - loss: 10.5032 - mean_absolute_error: 2.4605 - val_loss: 11.4940 - val_mean_absolute_error: 2.5811
Epoch 63/100
4840/4840 [==============================] - 8s 2ms/step - loss: 10.5024 - mean_absolute_error: 2.4613 - val_loss: 11.4948 - val_mean_absolute_error: 2.5813
Epoch 64/100
4840/4840 [==============================] - 6s 1ms/step - loss: 10.5030 - mean_absolute_error: 2.4611 - val_loss: 11.4967 - val_mean_absolute_error: 2.5821
Epoch 65/100
4840/4840 [==============================] - 13s 3ms/step - loss: 10.5030 - mean_absolute_error: 2.4627 - val_loss: 11.4951 - val_mean_absolute_error: 2.5804
Epoch 66/100
4840/4840 [==============================] - 18s 4ms/step - loss: 10.5029 - mean_absolute_error: 2.4619 - val_loss: 11.4955 - val_mean_absolute_error: 2.5803
Epoch 67/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5029 - mean_absolute_error: 2.4610 - val_loss: 11.4942 - val_mean_absolute_error: 2.5807
Epoch 68/100
4840/4840 [==============================] - 10s 2ms/step - loss: 10.5032 - mean_absolute_error: 2.4614 - val_loss: 11.4967 - val_mean_absolute_error: 2.5811
Epoch 69/100
4840/4840 [==============================] - 8s 2ms/step - loss: 10.5030 - mean_absolute_error: 2.4620 - val_loss: 11.4979 - val_mean_absolute_error: 2.5809
Epoch 70/100
4840/4840 [==============================] - 19s 4ms/step - loss: 10.5028 - mean_absolute_error: 2.4618 - val_loss: 11.4979 - val_mean_absolute_error: 2.5808
Epoch 71/100
4840/4840 [==============================] - 13s 3ms/step - loss: 10.5026 - mean_absolute_error: 2.4617 - val_loss: 11.4966 - val_mean_absolute_error: 2.5808
Epoch 72/100
4840/4840 [==============================] - 11s 2ms/step - loss: 10.5028 - mean_absolute_error: 2.4612 - val_loss: 11.4988 - val_mean_absolute_error: 2.5812
Epoch 73/100
4840/4840 [==============================] - 16s 3ms/step - loss: 10.5028 - mean_absolute_error: 2.4613 - val_loss: 11.4957 - val_mean_absolute_error: 2.5814
Epoch 74/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5028 - mean_absolute_error: 2.4613 - val_loss: 11.4969 - val_mean_absolute_error: 2.5813
Epoch 75/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5025 - mean_absolute_error: 2.4622 - val_loss: 11.4947 - val_mean_absolute_error: 2.5804
Epoch 76/100
4840/4840 [==============================] - 18s 4ms/step - loss: 10.5032 - mean_absolute_error: 2.4615 - val_loss: 11.4961 - val_mean_absolute_error: 2.5804
Epoch 77/100
4840/4840 [==============================] - 21s 4ms/step - loss: 10.5029 - mean_absolute_error: 2.4612 - val_loss: 11.4964 - val_mean_absolute_error: 2.5811
Epoch 78/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5032 - mean_absolute_error: 2.4617 - val_loss: 11.4925 - val_mean_absolute_error: 2.5802
Epoch 79/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5033 - mean_absolute_error: 2.4613 - val_loss: 11.4949 - val_mean_absolute_error: 2.5807
Epoch 80/100
4840/4840 [==============================] - 19s 4ms/step - loss: 10.5031 - mean_absolute_error: 2.4617 - val_loss: 11.4970 - val_mean_absolute_error: 2.5807
Epoch 81/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5026 - mean_absolute_error: 2.4619 - val_loss: 11.4956 - val_mean_absolute_error: 2.5805
Epoch 82/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5026 - mean_absolute_error: 2.4617 - val_loss: 11.4944 - val_mean_absolute_error: 2.5803
Epoch 83/100
4840/4840 [==============================] - 12s 2ms/step - loss: 10.5033 - mean_absolute_error: 2.4615 - val_loss: 11.4938 - val_mean_absolute_error: 2.5800
Epoch 84/100
4840/4840 [==============================] - 17s 4ms/step - loss: 10.5033 - mean_absolute_error: 2.4611 - val_loss: 11.4948 - val_mean_absolute_error: 2.5802
Epoch 85/100
4840/4840 [==============================] - 21s 4ms/step - loss: 10.5032 - mean_absolute_error: 2.4609 - val_loss: 11.4947 - val_mean_absolute_error: 2.5809
Epoch 86/100
4840/4840 [==============================] - 15s 3ms/step - loss: 10.5036 - mean_absolute_error: 2.4611 - val_loss: 11.4933 - val_mean_absolute_error: 2.5803
Epoch 87/100
4840/4840 [==============================] - 15s 3ms/step - loss: 10.5032 - mean_absolute_error: 2.4610 - val_loss: 11.4922 - val_mean_absolute_error: 2.5805
Epoch 88/100
4840/4840 [==============================] - 17s 3ms/step - loss: 10.5036 - mean_absolute_error: 2.4607 - val_loss: 11.4971 - val_mean_absolute_error: 2.5808
Epoch 89/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5029 - mean_absolute_error: 2.4615 - val_loss: 11.4988 - val_mean_absolute_error: 2.5811
Epoch 90/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5036 - mean_absolute_error: 2.4606 - val_loss: 11.4951 - val_mean_absolute_error: 2.5802
Epoch 91/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5034 - mean_absolute_error: 2.4605 - val_loss: 11.4964 - val_mean_absolute_error: 2.5811
Epoch 92/100
4840/4840 [==============================] - 18s 4ms/step - loss: 10.5029 - mean_absolute_error: 2.4618 - val_loss: 11.4968 - val_mean_absolute_error: 2.5813
Epoch 93/100
4840/4840 [==============================] - 14s 3ms/step - loss: 10.5034 - mean_absolute_error: 2.4612 - val_loss: 11.4989 - val_mean_absolute_error: 2.5809
Epoch 94/100
4840/4840 [==============================] - 19s 4ms/step - loss: 10.5033 - mean_absolute_error: 2.4613 - val_loss: 11.4981 - val_mean_absolute_error: 2.5808
Epoch 95/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5032 - mean_absolute_error: 2.4613 - val_loss: 11.4971 - val_mean_absolute_error: 2.5808
Epoch 96/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5028 - mean_absolute_error: 2.4607 - val_loss: 11.4959 - val_mean_absolute_error: 2.5816
Epoch 97/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5035 - mean_absolute_error: 2.4622 - val_loss: 11.4934 - val_mean_absolute_error: 2.5805
Epoch 98/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5027 - mean_absolute_error: 2.4619 - val_loss: 11.4938 - val_mean_absolute_error: 2.5810
Epoch 99/100
4840/4840 [==============================] - 15s 3ms/step - loss: 10.5025 - mean_absolute_error: 2.4619 - val_loss: 11.4962 - val_mean_absolute_error: 2.5804
Epoch 100/100
4840/4840 [==============================] - 20s 4ms/step - loss: 10.5030 - mean_absolute_error: 2.4611 - val_loss: 11.4978 - val_mean_absolute_error: 2.5811</code></pre>
</div>
</div>
<p>To measure the change in the <code>mean_absolute_error</code> statistic within my epochs (or run through the datasets) during the attempt to fit the Machine Learning model above as they were being completed, I made a line-graph visualization to see the fluctuation in the error as shown below.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Validation Mean Absolute Error throughout the fitting of the model across epochs</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>pd.Series(book_rec_history.history[<span class="st">"val_loss"</span>][<span class="dv">15</span>:]).plot(logy<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">"gold"</span>)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Validation Error"</span>)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Change in Validation Mean Absolute Error Across Epochs"</span>)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Minimum MSE:"</span>, <span class="bu">min</span>(book_rec_history.history[<span class="st">"val_loss"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-36-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Minimum MSE: 11.463703155517578</code></pre>
</div>
</div>
<p>With the Machine Learning model fitted, it would be a good time to evaluate the effectiveness of my model. Thus, I will calculate metrics (as shown below) such as <code>Precision Score</code>, <code>ROC-AUC (Receiver Operating Characteristic (Curve) - Area Under the Curve) Score</code>, <code>F1 Score</code>, <code>Recall Score</code>, and the <code>Confusion Matrix</code>. For the classification metrics, I applied a threshold rating of 5.0 or above to indicate as an acceptable rating to recommend a book, based on the logic that there would be more positive than negative reviews for that book-title, on average. All of the calcuations are shown in the following code snippet as well as its corresponding visualizations.</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>predicted_ratings <span class="op">=</span> model.predict(x<span class="op">=</span>(X_test[<span class="st">"New-User-ID"</span>], X_test[<span class="st">"New-ISBN"</span>])).flatten()</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>book_rec_history_model_loss, book_rec_history_model_accuracy <span class="op">=</span> model.evaluate(x<span class="op">=</span>(X_test[<span class="st">"New-User-ID"</span>], X_test[<span class="st">"New-ISBN"</span>]), y<span class="op">=</span>X_test[<span class="st">"Book-Rating"</span>])</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>book_rec_history_model_accuracy <span class="op">/=</span> <span class="dv">10</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Threshold the predicted ratings to binary-classified recommendations (e.g., using a threshold of &gt;= 5 for recommending book)</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>predicted_labels_bin_classify <span class="op">=</span> (predicted_ratings.copy() <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>actual_labels_bin_classify <span class="op">=</span> (X_test[<span class="st">"Book-Rating"</span>].copy() <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>actual_ratings_str <span class="op">=</span> predicted_labels_bin_classify.copy().astype(<span class="bu">int</span>)</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>predicted_ratings_str <span class="op">=</span> actual_labels_bin_classify.copy().astype(<span class="bu">int</span>)</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>clf_report <span class="op">=</span> pd.DataFrame(classification_report(y_true<span class="op">=</span>actual_ratings_str, y_pred<span class="op">=</span>predicted_ratings_str, output_dict<span class="op">=</span><span class="va">True</span>, zero_division<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>y_test_book_rating <span class="op">=</span> predicted_labels_bin_classify</span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>y_pred_book_rating <span class="op">=</span> actual_labels_bin_classify</span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>avg_precision_score <span class="op">=</span> average_precision_score(y_true<span class="op">=</span>actual_labels_bin_classify, y_score<span class="op">=</span>predicted_labels_bin_classify)</span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Output statistics for Average Precision, Accuracy, and ROC AUC scores as well as the classifcation &amp; confusion matrix reports</span></span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Results:</span><span class="ch">\n</span><span class="st">================================================"</span>)</span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average Precision Score (When Compared to Test Set): </span><span class="sc">{</span>avg_precision_score <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"_______________________________________________"</span>)</span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy Score (When Compared to Test Set): </span><span class="sc">{</span>book_rec_history_model_accuracy <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"_______________________________________________"</span>)</span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ROC AUC Score: </span><span class="sc">{</span>roc_auc_score(y_test_book_rating, y_pred_book_rating) <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"_______________________________________________"</span>)</span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"CLASSIFICATION REPORT:</span><span class="ch">\n</span><span class="sc">{</span>clf_report<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"_______________________________________________"</span>)</span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Confusion Matrix: </span><span class="ch">\n</span><span class="sc">{</span>confusion_matrix(y_test_book_rating, y_pred_book_rating)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Precision, Recall, and F1-score</span></span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a>precision, recall, f1_score, _ <span class="op">=</span> precision_recall_fscore_support(y_true<span class="op">=</span>actual_labels_bin_classify, y_pred<span class="op">=</span>predicted_labels_bin_classify, average<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a>model_performance_metrics: [<span class="bu">str</span>] <span class="op">=</span> [<span class="st">"Precision"</span>, <span class="st">"Recall"</span>, <span class="st">"F1_Score"</span>]</span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a>model_performance_metrics_values: [<span class="bu">float</span>] <span class="op">=</span> [precision, recall, f1_score]</span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb61-38"><a href="#cb61-38" aria-hidden="true" tabindex="-1"></a>plt.bar(model_performance_metrics, model_performance_metrics_values, color<span class="op">=</span>[<span class="st">'blue'</span>, <span class="st">'green'</span>, <span class="st">'orange'</span>])</span>
<span id="cb61-39"><a href="#cb61-39" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Metrics'</span>)</span>
<span id="cb61-40"><a href="#cb61-40" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Score'</span>)</span>
<span id="cb61-41"><a href="#cb61-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Recommendation Model Evaluation Metrics'</span>)</span>
<span id="cb61-42"><a href="#cb61-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb61-43"><a href="#cb61-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-44"><a href="#cb61-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the confusion matrix</span></span>
<span id="cb61-45"><a href="#cb61-45" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test_book_rating, y_pred_book_rating)</span>
<span id="cb61-46"><a href="#cb61-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-47"><a href="#cb61-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the confusion matrix</span></span>
<span id="cb61-48"><a href="#cb61-48" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb61-49"><a href="#cb61-49" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb61-50"><a href="#cb61-50" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb61-51"><a href="#cb61-51" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual Label'</span>)</span>
<span id="cb61-52"><a href="#cb61-52" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb61-53"><a href="#cb61-53" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>269/269 [==============================] - 0s 936us/step
269/269 [==============================] - 0s 1ms/step - loss: 11.4806 - mean_absolute_error: 2.5759
Test Results:
================================================
Average Precision Score (When Compared to Test Set): 39.60%
_______________________________________________
Accuracy Score (When Compared to Test Set): 25.76%)
_______________________________________________
ROC AUC Score: 72.25%
_______________________________________________
CLASSIFICATION REPORT:
                     0           1  accuracy    macro avg  weighted avg
precision     0.952672    0.253937  0.746397     0.603304      0.876983
recall        0.752998    0.692060  0.746397     0.722529      0.746397
f1-score      0.841147    0.371544  0.746397     0.606346      0.790279
support    7672.000000  932.000000  0.746397  8604.000000   8604.000000
_______________________________________________
Confusion Matrix: 
[[5777 1895]
 [ 287  645]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-37-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-37-output-3.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<ul>
<li><ol type="1">
<li></li>
</ol></li>
<li><ol start="2" type="1">
<li></li>
</ol></li>
<li><ol start="3" type="1">
<li></li>
</ol></li>
</ul>
</section>
<section id="reference-sources-and-citations-ieee-format" class="level2">
<h2 class="anchored" data-anchor-id="reference-sources-and-citations-ieee-format">Reference Sources and Citations (IEEE Format)</h2>
<p>To complete this blog post, I used the following online sources as references for developing this:</p>
<p>[1] Book Recommendation Dataset:</p>
<p>Möbius, “Book Recommendation Dataset”, Apr.-2023. [Online]. Available: https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset. [Accessed: 25-Sep.-2023].</p>
<p>[2] Tutorial on Basics of Machine Learning Recommendation Systems:</p>
<p>M. Ahammad, “Movie Recommender Systems Using Neural Network,” 2020. [Online]. Available: https://www.kaggle.com/code/mejbahahammad/movie-recommender-systems-using-neural-network. [Accessed: 25-Sep.-2023].</p>
<p>[3] Tutorial on Sample Visualizations for Machine Learning Recommendation Systems:</p>
<p>Great Learning Team, “Excerpts From a Masterclass on Movie Recommendation System,” 22-Aug.-2022. Available: https://www.mygreatlearning.com/blog/masterclass-on-movie-recommendation-system/. [Accessed: 26-Sep.2023].</p>
<p>[4] Tutorial on Evaluating Machine Learning Recommendation Systems:</p>
<p>A. Johannsdottir, “Implementing Your Own Recommmender Systems in Python”, 28-Nov.-2019. Available: https://www.cambridgespark.com/info/recommender-systems-in-python. [Accessed: 27-Sep.2023].</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>